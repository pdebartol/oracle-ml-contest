{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DOMAIN OF THE DATA\n",
    "<br>\n",
    " PPI network can be represented as a graph with a total of $\\space n = 56944 \\space$ nodes ( we split the data into two folds:    $\\space n_{train} = 44906 \\space$  and $\\space n_{test} = 12038 \\space$) \n",
    " where each specific protein is identified with a node. \n",
    " Furthermore each node is characterized with a <b>really sparse</b> binary feature \n",
    " vector $\\space x\\in \\{0,1\\}^{50} \\space$ and a list of undirected edges that explicits connections between nodes. \n",
    "\n",
    "In addition to the features, we have the labels  for the training set: a vector $l\\in \\{0,1\\}^{122}$ for each node.\n",
    "Our goal is to predict the labels of the test set with the best accuracy (F1 score will be evaluated). \n",
    "These are the data distributions:  \n",
    "\n",
    "\n",
    "  1 | 2\n",
    " - | - \n",
    "![alt](./images/Training_set_features.png) | ![alt](./images/Training_set_feature_elements.png)\n",
    "\n",
    " 3| 4 \n",
    " - | - \n",
    "![alt](./images/test_set_features.png) | ![alt](./images/Test_set_feature_elements.png)\n",
    "\n",
    "5| 6 \n",
    " - | - \n",
    "![alt](./images/nlabels.png) | ![alt](./images/label_component.png)\n",
    "\n",
    "\n",
    "'Feature10' ( which corresponds to the third element in the plot ) is costant to zero in each sample of the dataset and we delete it since it cannot express any causal correlation with the labels. Overall, the sparsity of the features suggests that we'll need to extract as much information as we can from graph structure.\n",
    "\n",
    "As far as labels are concerned, we notice that they are quite dense. Moreover, if we assume the independence between label classes, applying the law of large numbers, we can esteem the mean of occurences of each class in the test set from its mean in the training set  ( this will come in handy at the end ). The plots 2 and 4 show the same result for the features.\n",
    "<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import utils  \n",
    "from node2vec import Node2Vec  # NODE2VEC EMBEDDINGS \n",
    "import classifier as clf  # VERTEX CLASSIFIER\n",
    "import matplotlib.pyplot as plt  # PLOTTING\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "### LOADING THE DATA\n",
    "\n",
    "<br>\n",
    "<div>\n",
    "In the following section we define four foundamental matrices:\n",
    "    \n",
    "<br>\n",
    "<ul>\n",
    "    <li>$X_{train}\\in \\{0,1\\}^{n_{train}\\times49}$</li>\n",
    "    <br>\n",
    "    <li>$X_{test}\\in \\{0,1\\}^{n_{test}\\times49}$ </li>\n",
    "    <br>\n",
    "    <li>$X = \\begin{bmatrix}X_{train} \\\\ X_{test}\\end{bmatrix} \\in \\{0,1\\}^{n\\times49}$</li>\n",
    "    <br>\n",
    "    <li>$L\\in \\{0,1\\}^{n\\times122}$ \n",
    " </li>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOADING THE DATA\n",
    "vertices_train, vertices_test = utils.build_vertices()\n",
    "\n",
    "X_train_df = utils.build_dataframe(vertices_train, \"feature\")\n",
    "X_train_df = X_train_df.drop(['feature_10'], axis=1)  # DROP USELESS FEATURE\n",
    "\n",
    "X_test_df = utils.build_dataframe(vertices_test, \"feature\")\n",
    "X_test_df = X_test_df.drop(['feature_10'], axis=1)  # DROP USELESS FEATURE\n",
    "\n",
    "labels_df = utils.build_dataframe(vertices_train, \"label\", preserve_int_col_name=True)\n",
    "\n",
    "\n",
    "# BUILDING NUMPY MATRICES \n",
    "X_train = X_train_df.values\n",
    "X_test = X_test_df.values\n",
    "X = np.concatenate((X_train, X_test), axis=0)\n",
    "labels = labels_df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "Here we define our graph  $\\space G = (V,E)\\space$ that represents the PPI network and we explicit all the edges.\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "Then we build our masks for training and test set :\n",
    "\n",
    "<br>\n",
    "    \n",
    "<div>\n",
    "\n",
    "\n",
    "<ul>\n",
    "    <li>$idx_{train} =  \\begin{pmatrix} 0,1\\dots44905 \\end{pmatrix} $</li>\n",
    "    <br>\n",
    "    <li>$idx_{test} = \\begin{pmatrix} 44906,44907\\dots56943 \\end{pmatrix} $ </li>\n",
    "    <br>\n",
    "</ul>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MASK FOR TRAIN/TEST\n",
    "train_idx = range(X_train.shape[0])\n",
    "test_idx = range(X_train.shape[0],X.shape[0])\n",
    "\n",
    "# BUILDING THE GRAPH\n",
    "G = utils.build_graph() # ALSO REMOVES SELF-LOOPS\n",
    "G = G.to_directed()  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## NODE2VEC\n",
    "\n",
    "\n",
    "In our first approach we ignore the features matrix $\\space X \\space$ encoding each node with Node2Vec algorithm, using a definition of neighborhood as flexible as possible.\n",
    "\n",
    "$ Node2Vec(G) \\mapsto \\mathbb{R}^{128} \\space$ \n",
    "\n",
    "For every source node $u\\in V$ , we define $\\space N_{s}(u) \\subset V\\space$  as a network neighborhood of node $u$ generated through a sampling strategy $S$ described as follows:\n",
    "\n",
    "given a source node $\\space u\\space$, we simulate a random walk of fixed length $\\space l\\space$. Let $\\space c_{i}$ denote the $\\space i_{th}\\space$ node in the walk, starting with $c_{0} = u\\space$. Nodes $\\space c_{i} \\space$ are generated with the following distribution: $\\space P(c_{i} = x \\mid c_{i-1}=v)  =   \\begin{cases} \n",
    "      \\frac{\\pi_{vx}}{Z} & if \\space(v,x) \\in E \\\\\n",
    "      0 & otherwise\n",
    "   \\end{cases}\n",
    "$\n",
    "where $\\space \\pi_{vx} \\space$ is the unnormalized transition probability between nodes $\\space v \\space$ and $\\space x \\space$, and $\\space Z \\space$ is the normalizing constant. \n",
    "\n",
    "We consider a random walk that just traversed\n",
    "edge $(t, v)$ and now resides at node $v$. The walk now needs to decide on the next step so it evaluates the transition probabilities $\\pi_{vx}$ on edges $(v, x)$ leading from $v$. We set then the unnormalized transition probability to $\\space \\pi_{vx} =\\alpha_{pq}(t, x)\\cdot w_{vx}$, where $\\space \\alpha_{pq}(t, x) =  \\begin{cases} \n",
    "      \\frac{1}{p} & if \\space d_{tx}=0 \\\\\n",
    "       1 & if \\space d_{tx}=1 \\\\\n",
    "      \\frac{1}{q} & if \\space d_{tx}=2\n",
    "   \\end{cases}\\space\n",
    "$ and in our graph $\\space w = 1 \\space$ since the edges are unweighted. \n",
    "\n",
    "\n",
    "The use of two parameters $\\space p \\space$ and $\\space q \\space$ allowed us to combine in a single path breadth-first sampling and depth-first sampling. In particular the return parameter $\\space p \\space$  controls the likelihood of immediately revisiting a node in the walk while the parameter 'q' allows the search to differentiate between \"inward\" and \"outward\" nodes. Here we set $\\space p = 1 \\space$  and $\\space q =5 \\space$  biasing the walks close to node $\\space t \\space$ (BFS) in order to emphasize structural equivalence. We empirically choose the parameters taking into account the existence of connected components in the graph that might limit depth-first sampling.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "![alt](./images/node2vec.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GENERATING WALKS OVER THE GRAPH\n",
    "node2vec = Node2Vec(G, dimensions=128, walk_length=12, num_walks=10, p=1, q=5) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### SKIP-GRAM \n",
    "\n",
    "We proceed by applying the Skip-gram model. We seek to optimize the following objective function which maximizes the log-probability of observing a network neighborhood $\\space N_{S}(u)\\space$ for a node u conditioned on its encoded representation, given by f: \n",
    "\n",
    "$$\n",
    " \\max_{f} \\sum_{u \\in V} \\log P(N_{s}(u)\\mid f(u)) $$\n",
    "\n",
    "In order to make the optimization problem solvable we make two standard assumptions:\n",
    "\n",
    "• Conditional independence. We factorize the likelihood by assuming that the probability of observing a neighborhood node given the embedding representation of the source node is independent of  seeing any other neighborhood node:\n",
    "\n",
    "$$ P(N_{s}(u)\\mid f(u)) = \\prod_{n_{i} \\in N_{s}(u)}P(n_{i} \\mid f(u)) $$\n",
    "\n",
    "\n",
    "• Symmetry in feature space. A source node and neighborhood node have a symmetric effect over each other in features space. \n",
    "\n",
    "\n",
    "Accordingly, we model the conditional likelihood of every source-neighborhood node pair as a softmax unit parametrized by a dot product of their embeddings:\n",
    "\n",
    "$$P(n_{i} \\mid f(u)) = \\frac{\\exp(\\space f(n_{i}) \\cdot f(u))}{\\sum_{v \\in V}\\exp(f(v) \\cdot f(u)} $$\n",
    "\n",
    "\n",
    "With the above assumptions, the objective function simplifies to:\n",
    "\n",
    "$$ \\max_{f} \\sum_{u \\in V}\\bigg[-\\log Z_{u} + \\sum_{n_{i} \\in N_{s}(u)}f(n_{i} \\cdot f(u)\\bigg]$$\n",
    "\n",
    "which is a simple optimization problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FITTING THE SKIP-GRAM MODEL\n",
    "skipgram = node2vec.fit(window=8)\n",
    "\n",
    "\n",
    "#  SAVING OUR EMBEDDINGS\n",
    "embedding_n2v = skipgram[skipgram.wv.vocab]   \n",
    "np.save('./embedding/embedding_n2v.npy', embedding_n2v)  # SAVING AS  A .NPY FILE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### CLASSIFICATION \n",
    "\n",
    "Once we have mapped each node of the graph in a low-dimensional vector the task becomes a standard classification problem.\n",
    "\n",
    "Since we don't use the feature matrices during the embedding phase now we concatenate the features with the embeddings ( here PCA is not necessary since the overall dimension is acceptable ).\n",
    "\n",
    "Let's define our embeddings and our target matrix: \n",
    "\n",
    "<ul>\n",
    "    <li>$\\space E_{n2v} \\in \\mathbb{R}^{128}$</li>\n",
    "    <br>\n",
    "    <li>$ X_{n2v} = X \\mid E_{n2v}$</li>\n",
    "    <br>\n",
    "</ul>\n",
    "\n",
    "\n",
    "We use cross validation to avoid overfitting. Moreover, we consider  a weighted cross-entropy as loss function in order to balance the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X MATRIX FOR CLASSIFICATION\n",
    "train_embedding_n2v = embedding_n2v[train_idx]  # EXTRACTING TRAINING SET EMBEDDINGS\n",
    "test_embedding_n2v = embedding_n2v[test_idx]  #  EXTRACTING TEST SET EMBEDDING\n",
    "X_train_n2v = np.concatenate((X_train, train_embedding_n2v), axis=1)  #  FEATURES + EMBEDDING\n",
    "X_test_n2v = np.concatenate((X_test, test_embedding_n2v), axis=1)  # FEATURES + EMBEDDINGS\n",
    "\n",
    "\n",
    "#  TESTING VALIDATION ACCURACY\n",
    "clf.validation_accuracy(X_train_n2v, labels)\n",
    "\n",
    "#  TESTING TRAIN ACCURACY\n",
    "node2vec_model = clf.fit_model(X_train_n2v, labels)  # RETURNS TRAINED MODEL AND TRAIN ACCURACY\n",
    "\n",
    "\n",
    "\n",
    "#  MAKING PREDICTIONS\n",
    "node2vec_pred = node2vec_model.predict_proba(X_test_n2v) > 0.5  # EVALUATING PREDICTIONS\n",
    "node2vec_pred = utils.a_third_law(labels,node2vec_pred) \n",
    "\n",
    "\n",
    "utils.get_results('./results/node2vec_pred.csv',node2vec_pred, X_test_df)  # SAVING RESULTS IN A .CSV FOR KAGGLE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CONCLUSIONS ON NODE2VEC\n",
    "\n",
    "The algorithm provides competitive performance on the embedding task but  an accuracy of $0.43/0.44$  is not enough to be considered good. We can do better!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "## GRAPH CONVOLUTIONAL NETWORK\n",
    "\n",
    "In the previous approach we didn't take advantage of the feature matrix to build the embeddings.\n",
    "Now we aim to encode both graph structure and nodes' features in our embeddings using two graph convolutional networks. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GCN  ( Spectral Method )\n",
    "\n",
    "<br>\n",
    "Following the idea of T.N. Kipf and M.Welling, we directly encode the graph structure from its spectral representation using a semi-supervised neural network model $\\space f(X, A) \\space$ and then train on a supervised target for all nodes with labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from gcn.model import GCN \n",
    "from train  import train_model \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start with the extraction of the binary adjacency matrix $\\space A \\space$ from the graph; it is symmetric since the edges are undirected. <br>\n",
    "\n",
    "Then we perform this operation  $\\space \\tilde{A} = A + \\theta I \\space$\n",
    "to consider and set the importance of a node's own feature.\n",
    "\n",
    "Let's define the degree matrix  as $\\space \\tilde{D} = \\sum_{j}\\tilde{A_{ij}}$, it will be useful for normalizing the feature representations. Indeed, a propagation rule without a normalization implies that nodes with larger degrees have larger values in their features while nodes with smaller degrees have smaller values.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BUILDING ADJ MATRIX FOR GCN\n",
    "A = utils.adjacency_matrix_GCN(G, theta=1)  \n",
    "\n",
    "\n",
    "# DEFINING OUR PARAMETERS\n",
    "n_features = X.shape[1]\n",
    "n_classes = labels.shape[1]\n",
    "n_hidden = 32  #  NUMBER OF HIDDEN PARAMETERS IN OUR NET\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "#### PROPAGATION RULE\n",
    "\n",
    "The convolution operation on a graph is defined in the Fourier domain by computing the eigendecomposition of the graph Laplacian ( $\\space \\Delta = D - A\\space$ ). Thanks to a truncated espansion in terms of Chebyshev polynomial of the convolution filter (approximation 1) and a constraint in the number of parameters (approximation 2), as showed in [this paper](https://arxiv.org/abs/1609.02907) by T.N. Kipf and M.Welling, we can define the propagation rule as follows:\n",
    "\n",
    "$$\\begin{cases} H^{(l+1)}=\\sigma (\\tilde{D}^{\\frac{1}{2}}\\tilde{A}\\tilde{D}^{\\frac{1}{2}}H^{(l)}W^{(l)}) \\\\\n",
    "       H^{(0)}=X\n",
    "   \\end{cases}\n",
    "$$\n",
    "<br>\n",
    "\n",
    "where $H^{(l)}$ are the hidden states.\n",
    "\n",
    "Our goal is to obtain the best possible values of the weights matrix $\\space W \\space$ that minimize the cross entropy loss function. We reach this objective training our model with backpropagation.\n",
    "\n",
    "\n",
    "After some trials and errors we set $2$ hidden layers with $16$ hidden parameters\n",
    "(we found out that accuracy does not get better incrementing layers or parameters). \n",
    "The $2$ layers in our model are forcing each node to combine its features with his neighbors until the second order of proximity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### DROPOUT\n",
    "\n",
    "In order to prevent the neural network from overfitting we apply a dropout rate of $0.5$. The key idea is to randomly drop units out of the neural network, along with their connections, during the training. \n",
    "\n",
    "![alt](./images/dropout.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATING AND TRAINING OUR MODEL\n",
    "\n",
    "gcn_model = GCN(n_features, n_hidden, n_classes, dropout=0.5)\n",
    "embedding_gcn = train_model(gcn_model, X, A, labels, train_idx, epochs=50, lr=0.005, wd=5e-3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  EXTRACTING EMBEDDINGS \n",
    "train_embedding_gcn = embedding_gcn[train_idx]\n",
    "test_embedding_gcn = embedding_gcn[test_idx]\n",
    "\n",
    "\n",
    "#  TESTING TRAIN ACCURACY (SIGMOID TRESHOLD SET AT 0.4 )\n",
    "gcn_train_pred = torch.sigmoid(train_embedding_gcn).detach().numpy() > 0.4 \n",
    "utils.get_score(gcn_train_pred, labels)  # HAMMING ACCURACY, F1-MICRO, F1-MACRO\n",
    "\n",
    "#  SAVING THE EMBEDDING\n",
    "np.save('./embedding/embedding_gcn.npy', embedding_gcn.detach().numpy())  # .NPY FILE\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  MAKING OUR PREDICTION\n",
    "gcn_test_pred = torch.sigmoid(test_embedding_gcn).detach().numpy() > 0.5  # PREDICTIONS ON TEST SET\n",
    "gcn_test_pred = utils.a_third_law(labels,gcn_test_pred) # 0.475 accuracy\n",
    "utils.get_results('./results/gcn_pred.csv',gcn_test_pred, X_test_df)  # SAVING RESULTS IN A .CSV \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each embedding $ E \\in \\mathbb{R}^{122} $ . We can map it in $  \\{0,1\\}^{122}$ applying a  sigmoid function and then a  treshold.\n",
    " \n",
    "As we expected, given the structural complexity of the GCN model, our accuracy increased.\n",
    "\n",
    "However, the increase in accuracy is minimal and the score obtained is not enough.\n",
    "We start wondering if our sparse features matrix $\\space X \\space$ contains enough information in order to perform this multi-label classification task.\n",
    "\n",
    "Before jumping to conclusions we'll try to implement  GraphSAGE and GAT, other two state-of-the-art algorithms for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sage.model import SAGE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GraphSAGE (spatial method)\n",
    "  \n",
    "Aiming to make our model richer and richer we implement now a second graph neural network called GraphSAGE. Unlike GCN, GraphSAGE is a spatial method with an <b> inductive </b> framework that does not consider spectral representation of the graph.\n",
    "It's an inductive method because it doesn't need to retrain all the model from scratch for each new training example, as a consequence it can efficiently generates node embeddings for previously unseen data. \n",
    "Furthermore, it is a spatial (non-spectral) approach because it directly defines convolutions on the graph, operating on spatially close neighbors.\n",
    "\n",
    "The intuition behind GraphSAGE is that at each iteration, nodes aggregate information from their local neighbors, and as this process iterates, nodes incrementally gain more and more information from further reaches of the graph.\n",
    "At first, each node $\\space v \\in V \\space$ aggregates the representations of the nodes in its immediate neighborhood, into a single vector. This aggregation step depends on the representations generated at the previous iteration of the outer loop (i.e., $\\space k-1 \\space$), and the $\\space k = 0 \\space$ representations are defined as the initial node features. \n",
    "\n",
    "After aggregating the neighboring feature vectors, GraphSAGE  concatenates the node’s current representation with the aggregated neighborhood vector, and this concatenated vector is fed through a fully connected layer with nonlinear activation function $\\sigma$ .\n",
    "\n",
    "We chose as aggregator function the element-wise mean aggreator.\n",
    "\n",
    "This pseudo-code explains well all the steps:\n",
    "\n",
    "![alt](./images/sage.jpg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#  CREATING THE MODEL\n",
    "edge_list = torch.LongTensor(utils.edge_list_SAGE())  # list of all the edges\n",
    "sage_model = SAGE(n_features, n_hidden, n_classes, 0.5)\n",
    "\n",
    "\n",
    "#  TRAINING THE MODEL \n",
    "embedding_sage = train_model(sage_model, X, edge_list, labels, train_idx, epochs=25, lr=0.1,wd=5e-3)\n",
    "sage_train_pred = torch.sigmoid(embedding_sage[train_idx]).detach().numpy() > 0.5# TRESHOLD ON SIGMOID PROBABILITIES\n",
    "sage_train_pred = utils.a_third_law(labels,sage_train_pred)\n",
    "utils.get_score(sage_train_pred, labels)  # HAMMING ACCURACY, F1-MICRO, F1-MACRO\n",
    "\n",
    "\n",
    "#  SAVING THE EMBEDDING\n",
    "np.save('./embedding/embedding_sage.npy', embedding_sage.detach().numpy())  # .NPY FILE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  MAKING OUR PREDICTION\n",
    "sage_test_pred = torch.sigmoid(embedding_sage[test_idx]).detach().numpy() > 0.5  # PREDICTIONS ON TEST SET\n",
    "sage_test_pred = utils.a_third_law(labels,sage_test_pred) # BEST SAGE 0.477\n",
    "utils.get_results('./results/sage_test_pred.csv',sage_test_pred, X_test_df)  # SAVING RESULTS IN A .CSV \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the aggregation function is defined we train the model as with GCN. Here the parameters that we want to train are the ones defining the AGGREGATE and CONCAT functions in the 4th and 5th line of Algorithm 1. Each embedding $ E \\in \\mathbb{R}^{122} $, we map it in $  \\{0,1\\}^{122}$ applying a  sigmoid function and then a  treshold.\n",
    " \n",
    "\n",
    "Despite the efforts GraphSAGE performs with an accurancy between 0.44 and 0.46 on the test set, almost as the previous alghorithms. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before implementing GAT we'll try to combine the embedding methods we've seen so far in order to join their strenghts.\n",
    "In doing so we don't want to enlarge the hypothesis space too much, therefore when we compose new node embeddings with doubled dimension we consider only the most relevant components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = np.concatenate((embedding_n2v,embedding_sage),axis=1)  # N2V EMBEDDING concatenated SAGE EMBEDDING\n",
    "clf.validation_accuracy(Y[train_idx],labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to get a genuine accuracy from these concatenations we run a cross-validation on the training set. \n",
    "\n",
    "However both GraphSAGE$\\mid$Node2Vec (roughly $0.425$ F1-Micro-Average) and  GCN$\\mid$Node2Vec get worse accuracy than individual embeddings.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 64)\n",
    "Y_pca = pca.fit_transform(Y)  #  250 --> 64\n",
    "print('Explained variance: ',np.sum(pca.explained_variance_ratio_))  #  GOOD EXPLAINED VARIANCE\n",
    "clf.validation_accuracy(Y_pca[train_idx],labels)     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even the principal compenent analysis, that maps these new embeddings of  250 features in a low-dimensional space considering the 64 directions of maximum variance, does not improve our predictions. \n",
    "We also combine all the different models' predictions obtaining similar results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph Attention Network (GAT)\n",
    "\n",
    "A last resort for our multi-label vertex classification problem is to implement GAT. Indeed, we read in  [this paper](https://arxiv.org/abs/1710.10903) that GAT can reach an accuracy of roughly $0.973$ on our protein-protein interactions network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gat.ppi import PPI\n",
    "from gat.model import GAT\n",
    "from gat.training import train,test\n",
    "from torch_geometric.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Graph attention network is more sophisticated than previous graph neural networks. The idea is to compute the hidden representations of each node in the graph, by aggregating its neighbors under the rules of an  attention strategy. The attention architecture has several interesting properties: the operation is efficient, since it is parallelizable across node neighbors pairs and the model is directly applicable to inductive learning problems (as GraphSAGE), including tasks where the model has to generalize for completely unseen graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  LOADING DATASETS \n",
    "train_dataset = PPI('./gat',split='train')\n",
    "test_dataset = PPI('./gat',split='test')\n",
    "valid_dataset = PPI('./gat',split='valid')  #  LET'S KEEP SOME TRAINING SAMPLES FOR VALIDATION..\n",
    "\n",
    "\n",
    "#  BATCH TRAINING.. \n",
    "train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=2, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to obtain sufficient expressive power to transform the input features into higher-level features, as an initial step, we apply to every node a shared learnable linear transformation parametrized by a weight matrix:\n",
    "\n",
    "$$z_i=W\\vec{h_i} \\quad \\forall i=1,..,n$$\n",
    "\n",
    "Then, a shared attentional mechanism $a$ computes attention coefficients that indicate the importance of node $j$'s features to node $i$:\n",
    "\n",
    "$$e_{ij}=a(W\\vec{h_i},W\\vec{h_j})=LeakyReLU(\\vec{a}^T(W\\vec{h_i}||W\\vec{h_j}) \\quad\\quad \\forall i=1,..,n \\quad \\forall j\\in N_i$$\n",
    "\n",
    "This attention mechanism can be considered as generalization of the GCN  were  each node has not the same influence on its neighbors.  Indeed, we already introduced sort of an attention  coefficent in our model with the GCN $\\theta$ parameter ( we added theta-times the identity matrix to the adjacency matrix to emphasize the importance of self-loops ).\n",
    "\n",
    "To make coefficients easily comparable across different nodes, we normalize them across all choices of j using the softmax function:\n",
    "\n",
    "$$ a_{ij}=softmax_j (e_{ij})=\\frac {exp(e_{ij})}{\\sum_{k \\in N_i}exp(e_{ik})}=\\frac {exp(LeakyReLU(\\vec{a}^T(W\\vec{h_i}||W\\vec{h_j}))}{\\sum_{k \\in N_i}exp(LeakyReLU(\\vec{a}^T(W\\vec{h_i}||W\\vec{h_k}))} \\quad\\quad \\forall i=1,..,n \\quad \\forall j\\in N_i$$\n",
    "\n",
    "Once obtained, the normalized attention coefficients are used to compute a linear combination of their features. These will be the final output features for every node:\n",
    "\n",
    "$$\\vec{h'_i}=\\sigma(\\sum_{j\\in N_i}a_{ij} W\\vec{h_j}) \\quad \\forall i=1,..,n$$\n",
    "\n",
    "To better stabilize the learning process we also extend the mechanism, implementing multi-head attention:\n",
    "\n",
    "$$\\vec{h'_i}=\\parallel_{k=1}^{K} \\sigma(\\sum_{j\\in N_i}a_{ij}^k W^k\\vec{h_j}) \\quad \\forall i=1,..,n$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  BUILDING AND TRAINING OUR MODEL\n",
    "model = GAT(n_features,n_classes)\n",
    "for epoch in range(1, 60):\n",
    "    loss = train(model,train_loader) \n",
    "    acc = test(model,valid_loader) \n",
    "    print('Epoch: {:02d}, Loss: {:.4f}, Acc: {:.4f}'.format(epoch, loss, acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the learning task, we apply a three-layer GAT model. Both of the first two layers consist of K = 4 attention heads computing F0 = 256 features, followed by an ELU nonlinearity. The final layer is used for (multi-label) classification:\n",
    "K = 6 attention heads, each computing 122 features that are averaged and followed by a logistic sigmoid activation.\n",
    "\n",
    "\n",
    "In order to improve even more the accuracy, with some  statistical considerations we impose  the most probable classes of labels to 1 without taking into account our prediction. This 'trick' improves our score of $0.02$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  MAKING PREDICTIONS\n",
    "model.cpu()\n",
    "for data in test_loader:    \n",
    "    out = model(data.x,data.edge_index)\n",
    "    \n",
    "pred = out.float().cpu() > 0\n",
    "pred = utils.a_third_law(labels,pred)\n",
    "\n",
    "utils.get_results('./results/gat_pred.csv',pred, X_test_df)  # SAVING RESULTS IN A .CSV "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Oooooooo... 0.5207!!! This is our best score  but again.. it is not so good. Is it possible to reach the same F1 score reported in the paper? It turns out that our dataset is a bit different.\n",
    "\n",
    "Graph and labels are the same but features are different: instead of being binary, their features matrix  $ X \\in [0,1]^{50}$ (it's continuos not discrete). Therefore, we guess that our features matrix is the paper's matrix activated with a non-liner function (probabily a simple step function). <br><br>\n",
    "Eventually, we can set our mind at rest: <b>our data does not contain enough information in order to reach a good accuracy</b>. \n",
    "However, this doesn't mean that all the embeddings we have built are useless: each one is a simpler structure where we store in a better way the sparse informations of the dataset.\n",
    "\n",
    "\n",
    "To emphasize how bad are our predictions, we now present our simple statistical algorithm that obtains almost the same accuracy as GAT and considers only the labels.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (NAIVE) STATISTICAL APPROACH\n",
    "\n",
    "We want to obtain the best accuracy possible basing our predictions only on  statistical considerations about labels' distribution. \n",
    "With this data we cannot predict the probability of a node to have a $1$ in a single element of its label. \n",
    "\n",
    "We don't want to randomly build  our predictions, therefore given a label class out of the $122$ we have to decide if it is set to $1$ or to $0$ for all the nodes in the test set.<br>\n",
    "\n",
    "To  decide if a given class should be $0$ or $1$ we define a vector $L_{mean}\\in [0,1]^{122}$ as follows:<br><br>\n",
    "$$ L_{mean}(i) = \\frac{\\mid\\{v\\mid L_{v,i}=1\\}\\mid}{n_{train}}$$ <br>\n",
    "$L_{mean}$ rapresents the mean of each label class in the training set. In the very beginning, we observed  that for the Central Limit Theorem, each one of these values should tend to the same mean in the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmean = utils.get_lmean(labels)    \n",
    "lmean = utils.sort_lmean(lmean)  #  DESCENDING ORDER "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea is to force $1$ to a number $s$ of label classes $i$ if $L_{mean}(i)$ is 'big enough'. We need to  define what 'big enough' actually means. \n",
    "\n",
    "We reorder the element of $L_{mean}$ from the biggest to the smallest and then evaluate $V(s)$, an  approximation of $F1$.\n",
    "\n",
    "$$V(s) = 2\\cdot \\frac {\\sum_{i=1}^{s} L_{mean}(i)}{\\sum_{i=1}^{122} L_{mean}(i) + n_{train}\\cdot s} \\simeq F1(s)$$\n",
    "\n",
    "The variable $s$  goes from $1$ to $122$ and expresses the number of activated classes, starting with the one with bigger mean in the training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "A = 0\n",
    "k = 0\n",
    "f1_values = np.zeros(lmean.shape[0])\n",
    "for i in range(lmean.shape[0]):\n",
    "    k += lmean[i][0]\n",
    "for s in range(lmean.shape[0]):\n",
    "    A += lmean[s][0]\n",
    "    f1 = 2 * A / (k+X_train.shape[0]*(s+1))\n",
    "    f1_values[s] = f1\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating the function $V$ in all his domain $\\{1,2,...,122\\}$ and considering its maximum we find the value of $s$ that maximize our strategy and an esteem of its relative F1 score:<br>\n",
    "$$s_{max}=57$$ <br>\n",
    "$$V(s_{max})=0.527$$ <br>\n",
    "The following plot rapresents the trend of $V(s)$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f27bdfecac8>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.plot(f1_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = lmean_f[:np.argmax(f1_values),1]\n",
    "pred = np.zeros((X_test.shape[0],labels.shape[1]))\n",
    "\n",
    "for col in range(labels.shape[1]):\n",
    "    for i in range(np.argmax(f1_values)):\n",
    "        if(mask[i] == col):\n",
    "            pred[:,col] =1 \n",
    "            \n",
    "utils.get_results('./results/stat.csv',pred, X_test_df)  # SAVING RESULTS IN A .CSV  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We obtain an accuracy of $0.485$ on the test set which is in line with our esteem.\n",
    "\n",
    "On this dataset, <b> our 'naive' algorithm is more accurate than  GCN, Node2Vec,GraphSAGE </b> and their concatenations as far as vertex classification is concerned. Furthermore, it predicts a constant label for each element in the test set without taking into account graph or features. \n",
    "\n",
    "This result allows us to  emphasize a last important conlusion: <br>\n",
    "\n",
    "<b>$$Machine\\space Learning\\space is\\space not\\space magic!$$</b>\n",
    "\n",
    "If data is not good enough, we can't pretend flawless performance even from the best machine learning algorithm for that specific task. In this specific case, statistic alone performes better than state-of-the-art algorithms that are not able learn from the data.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
